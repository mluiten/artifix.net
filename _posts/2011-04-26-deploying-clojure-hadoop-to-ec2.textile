---
layout: post

title: Clojure map/reduce jobs using Hadoop on Amazon EC2
excerpt: How's that for buzzwords, huh? I'm currently working on a project that requires me to run the clojure-hadoop library on a EC2 cluster. This blog is a quick rundown on how set up the basic infrastructure.

author: Menno Luiten
---


h3. Whirr - running Hadoop in the cloud

"Whirr":http://incubator.apache.org/whirr/ is an Apache incubator project designed to provide a uniform API to deploy distributed services to a cloud provider. In this case, I'm deploying the Hadoop library to Amazon EC2, but other services include Cassandra, Zookeeper and HBase and Rackspace Cloud Servers is also supported as a provider, with the promise of more to come.

There are two Whirr libraries; a set of python scripts (which seemingly only supports the Hadoop and EC2 combo) and the newer Java-based scripts. The latter uses "jclouds":http://code.google.com/p/jclouds/, which seems to enable most of the cloud-agnostic features of Whirr.

Using the most up-to-date techniques, I decided to use the Java libraries. So, after downloading the latest Whirr:

{% highlight console %}
mluiten@box:~$ tar zxf whirr-0.4.0-incubator.tar.gz
mluiten@box:~$ test
{% endhighlight %}

Then we should add (or uncomment) the following lines to the %(highlight)/recipes/hadoop-ec2.properties% file.

{% highlight ini %}
whirr.hadoop-install-function=install_cdh_hadoop
whirr.hadoop-configure-function=configure_cdh_hadoop
{% endhighlight %}

h3. Installing CDH3 locally

We can now whirr up a cluster of CDH3 hadoop machines using the %(highlight)whirr launch-cluster% command, but to inject jobs into this cluster we need to install CDH3 locally as well. Luckily, Cloudera has made this exceptionally easy.

h3. clojure-hadoop

{% highlight clojure %}
(defn gentree
    "Generates a tree with specified depth and width in prefix notation
     e.g. (+ (- 1 2) (* 3 4))"
     [tree depth width]
     (if (zero? depth)
         (concat tree (repeatedly width #(+ 1 (rand-int 5))))
         (map (fn [_] (conj (gentree tree (dec depth) width) (rand-nth operators))) (range width))))
{% endhighlight %}

h3. Executing the job using lein uberjar

All we need now, is to inject the newly created clojure-hadoop job into the whirred-up Hadoop cluster. To do this, we need to package the clojure files, together with clojure-hadoop and all other libraries we depend on. A easy way to deal with this is to use Leiningen.
